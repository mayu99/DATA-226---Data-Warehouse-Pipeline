# -*- coding: utf-8 -*-
"""Homework_6_new.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16C03ZngI3W5NcjSkXSiN90a43jdfAVyo
"""

# Importing necessary libraries
from airflow import DAG
from airflow.models import Variable
from airflow.decorators import task
from airflow.providers.snowflake.hooks.snowflake import SnowflakeHook
from datetime import timedelta, datetime
import requests

# Function to return Snowflake connection
def return_snowflake_conn():
    hook = SnowflakeHook(snowflake_conn_id='snowflake_conn')
    return hook.get_conn().cursor()

# Extract stock data task
@task
def extract(symbol, api_key):
    url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={api_key}'
    r = requests.get(url)
    data = r.json()

    if 'Time Series (Daily)' not in data:
        raise ValueError(f"Error retrieving data for {symbol}: {data.get('Error Message', 'Unknown error')}")

    return data["Time Series (Daily)"]

# Extract last 90 days of stock data task
@task
def extract_last_90d_price(data):
    end_date = datetime.now()
    start_date = end_date - timedelta(days=90)
    results = []

    for d in sorted(data, reverse=True):
        stock_date = datetime.strptime(d, "%Y-%m-%d")
        if start_date <= stock_date <= end_date:
            stock_info = data[d]
            stock_info["date"] = d
            results.append(stock_info)
        if len(results) == 90:
            break
    return results

# Load stock data into Snowflake
@task
def load_stock_data(data, table_name):
    cur = return_snowflake_conn()

    merge_sql = f"""
    MERGE INTO {table_name} AS target
    USING (SELECT %(date)s AS date, %(open)s AS open, %(high)s AS high, %(low)s AS low, %(close)s AS close, %(volume)s AS volume) AS source
    ON target.date = source.date
    WHEN MATCHED THEN
        UPDATE SET
            open = source.open,
            high = source.high,
            low = source.low,
            close = source.close,
            volume = source.volume
    WHEN NOT MATCHED THEN
        INSERT (date, open, high, low, close, volume)
        VALUES (source.date, source.open, source.high, source.low, source.close, source.volume);
    """

    for record in data:
        record_to_insert = {
            'date': record['date'],
            'open': record['1. open'],
            'high': record['2. high'],
            'low': record['3. low'],
            'close': record['4. close'],
            'volume': record['5. volume']
        }
        cur.execute(merge_sql, record_to_insert)
    cur.execute("COMMIT;")
    print("Data inserted successfully!")

# Defining the DAG
with DAG(
    dag_id='Stock_prediction_AAPL',
    start_date=datetime(2024, 10, 8),
    catchup=False,
    schedule='30 20 * * *',
    default_args={
        'retries': 1,
        'retry_delay': timedelta(minutes=5),
    },
    tags=['ETL']
) as dag:

    api_key = Variable.get("api_key")
    symbol = "AAPL"
    target_table = "dev.raw_data.stock_price"

    raw_data = extract(symbol, api_key)
    lines = extract_last_90d_price(raw_data)
    load_stock_data(lines, target_table)

    # Task dependencies
    raw_data >> lines >> load_stock_data(lines, target_table)